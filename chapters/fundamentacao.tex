
\chapter{Fundamentação Teórica}\label{fundamentacao}

Este capítulo apresenta os conceitos básicos que envolvem o tema da pesquisa, assim como descreve os trabalhos correlatos a este, para melhor entendimento do contexto em que se encontra as pesquisas em LLM's.

\section{Enade}
O Exame Nacional de Desempenho dos Estudantes (ENADE) constitui um dos principais instrumentos do Sistema Nacional de Avaliação da Educação Superior (SINAES), instituído pela Lei nº 10.861, de 14 de abril de 2004. O SINAES foi concebido como uma política pública de avaliação capaz de assegurar e promover a qualidade da educação superior brasileira, a partir de uma abordagem formativa, diagnóstica e integradora, que considera dimensões pedagógicas, institucionais e de desempenho discente \cite{brasil2004}.

O ENADE tem como principal objetivo avaliar o rendimento dos estudantes em relação aos conteúdos previstos nas Diretrizes Curriculares Nacionais (DCNs) dos respectivos cursos, bem como suas competências para compreender temas externos ao âmbito específico da profissão, situando-se na realidade social, econômica, cultural e política do país. Ao avaliar estudantes ingressantes e concluintes, o exame permite observar a evolução da aprendizagem ao longo da formação acadêmica, sendo seus resultados fundamentais para compor indicadores como o Conceito Preliminar de Curso (CPC) e o Índice Geral de Cursos (IGC), que subsidiam processos de regulação, supervisão e melhoria da qualidade da educação superior no Brasil \cite{inep2023}.

Sob uma perspectiva teórica, o ENADE também se apresenta como um mecanismo indutor da qualidade, na medida em que seus resultados não apenas retratam o desempenho dos estudantes, mas também impulsionam processos de autorreflexão institucional, revisão de projetos pedagógicos, atualização curricular e aprimoramento da gestão acadêmica. Conforme aponta \parencite{dias2003}, a avaliação no contexto da educação superior deve ser compreendida como um instrumento de construção coletiva, capaz de orientar transformações qualitativas, evitando uma lógica meramente classificatória ou competitiva. Assim, a efetividade do ENADE depende do engajamento da comunidade acadêmica  docentes, discentes e gestores  que, ao se apropriar dos seus resultados, pode utilizá-los como base para ações de melhoria contínua, alinhadas às exigências da sociedade e do mercado de trabalho.

Dessa forma, o ENADE se consolida como um dispositivo fundamental para a promoção de uma cultura avaliativa nas instituições de ensino superior, sendo não apenas uma exigência legal, mas uma oportunidade de aprimoramento dos processos formativos e de fortalecimento do compromisso social da educação superior brasileira.

\section{LLM - Grande Modelo de Linguagem}

Grandes Modelos de Linguagem (\textit{Large Language Models}, LLM's) representam uma quebra de paradigma no uso da Inteligência Artificial (IA)\cite{raposo2024avaliaccao}. Os LLM's aprenderam a entender padrões a partir de grandes quantidades de textos de exemplo e a gerar respostas coerentes. Esses padrões identificam distribuições de probabilidades para sequências de palavras, que podem ser empregadas para gerar textos sintéticos \cite{peres2023grandes}.

Uma das características fundamentais dos LLM's reside na sua elevada capacidade computacional, diretamente relacionada à quantidade massiva de parâmetros e ao volume expressivo de dados utilizados em seu treinamento. Esses modelos são projetados para aprender padrões linguísticos complexos por meio de técnicas avançadas de aprendizado profundo (deep learning), particularmente baseadas na arquitetura Transformer, que permite processar e modelar relações contextuais em grandes sequências de texto.

 A partir da exposição a extensos conjuntos de dados textuais  provenientes de livros, artigos, sites, fóruns e outras fontes , os LLM's desenvolvem a habilidade de reconhecer estruturas sintáticas, relações semânticas e padrões discursivos presentes na linguagem natural. Dessa forma, são capazes não apenas de compreender e interpretar o conteúdo textual, mas também de gerar respostas e textos que se assemelham, em termos de coerência e fluidez, à produção humana.

 Essas capacidades permitem que os LLM's sejam aplicados em uma ampla gama de tarefas dentro do campo de PLN, como, por exemplo, tradução automática de idiomas, geração de textos originais, elaboração de resumos automáticos, análise de sentimentos, detecção de tópicos e desenvolvimento de sistemas inteligentes de perguntas e respostas \cite{eze2025}. Ademais, a precisão e a sofisticação desses modelos em lidar com a linguagem tornam possível sua utilização em contextos cada vez mais desafiadores e especializados, tanto no meio acadêmico quanto no mercado.
 
\section{Evolução da PLN até a introdução das LLM's}
A literatura aborda que o início dos estudos de PLN remonta à década de 50, onde Alan Turing propôs em seu artigo intitulado "Computing Machinery and Intelligence" o tão conhecido como "Teste de Turing" como algo a se definir como critério de inteligência\cite{jurafsky2023slp}. Esse teste deu a possibilidade de poder fazer máquinas pensarem e assim trouxe mais motivação aos inicio estudo na PLN.

Entre as décadas de 1950-1960 ouve os primeiro avanços e demonstração de um sistema de tradução automatica. Atráves da colaboração entre IBM e Georgetown University em que teve Léon Dostert como uma das figuras centrais desse projeto que consistiu em fazer uma tradução automatica do russo para o inglês. O estudo feito em pequena escala teve um total de 250 palavras e seis regras gramaticais; ainda assim, foi considerado um sucesso, pois o sistema demonstrou a capacidade de tradução, mesmo sendo para trechos curtos \cite{historyofinformationFirstPublic}.

Entre as décadas de 1960-1970 no MIT Artificial Intelligence Laboratory Joseph Weizenbaum criou um programa intitulado ELIZA, esse programa tinha a finalidade de se passar por um terapeuta, o programa era simples ao ponto de oferecer respostas pré-definidas aos usuários para fazer eles pensarem que estariam se comunicando com alguém que entendia o que lhe era passado. Considerado o primeiro chatbot, foi um caso inicial ao teste de Turing\cite{elizachat}. Nesse período também houve o SHRDLU criado por Terry Winograd no MIT no Artificial Intelligence Laboratory, o SHRDLU era capaz de compreender e executar comandos complexos, responder a perguntas sobre o estado do mundo, pedir esclarecimento quando necessário, raciocinar sobre possibilidades, aprender novas definições e até mesmo explicar o raciocínio por trás de suas ações\cite{shrdlu2025}.

Entre as décadas de 1980 e 1990, houve uma transição no Processamento de Linguagem Natural (PLN) para abordagens mais estatísticas, baseadas em grandes corpora de textos \cite{jurafsky2023slp3}. Destacou-se, nesse período, o uso dos Modelos de Markov Ocultos (Hidden Markov Models – HMMs), especialmente em tarefas como reconhecimento de fala e etiquetagem gramatical (POS tagging) \cite{jelinek1997statistical}. Os métodos estatísticos se consolidaram com a expansão dos modelos n-gram e com o desenvolvimento dos Modelos IBM 1 a 5, que formaram a base para os sistemas de tradução automática estatística (SMT) \cite{brown1993mathematics}. Além disso, a criação do Penn Treebank, em 1993, forneceu um corpus sintaticamente anotado de grande escala, que se tornou referência para o treinamento e avaliação de parsers probabilísticos \cite{marcus1993treebank}. A década também foi marcada pela realização das Message Understanding Conferences (MUCs), que impulsionaram as pesquisas em extração de informação (Information Extraction – IE) e promoveram a padronização de benchmarks para tarefas como reconhecimento de entidades nomeadas (NER) e resolução de co-referência \cite{grishman1996muc6}.

Entre as décadas de 2000–2010, com os avanços provenientes da década passada, culminaram também em avanços nos algoritmos utilizados na PLN tem-se uma adoção em larga escala de algoritmos supervisionados como Máquinas de Vetores de Suporte (SVMs), Modelos de Máxima Entropia e principalmente os Conditional Random Fields (CRFs), aplicados com sucesso em tarefas como reconhecimento de entidades nomeadas, POS tagging e parsing sintático \cite{lafferty2001crf}. Nesse período, também se estabeleceu o domínio da tradução automática estatística baseada em frases, com o desenvolvimento de ferramentas como o Moses \cite{koehn2007moses}, que substituíram os antigos modelos palavra-a-palavra (word-based). Paralelamente, houve uma inovação no uso de representações vetoriais para palavras: modelos como o Latent Semantic Analysis (LSA) já vinham sendo utilizados, mas o grande marco foi o trabalho de \textcite{bengio2003neural}, que introduziu o primeiro modelo de linguagem neural, propondo a ideia de treinar representações distribuídas de palavras em redes neurais. Esses avanços foram suportados pelo crescimento dos corpora anotados como o Penn Treebank e a organização de desafios como CoNLL-2003 e SemEval, que padronizaram benchmarks para tarefas como NER e análise de sentimentos. Com isso, a década de 2000 solidificou as bases estatísticas do PLN e iniciou a transição para abordagens neurais mais sofisticadas que viriam na década seguinte.

Entre as décadas de 2010–2017, tiveram novas revoluções significativas com a adoção crescente de técnicas de aprendizado profundo. Modelos de redes neurais recorrentes (RNNs), especialmente as variações LSTM(Long Short-Term Memory) e GRU(Gated Recurrent Unit), passaram a ser amplamente utilizados em tarefas sequenciais como análise de sentimentos, tradução automática e resposta a perguntas \cite{cho2014rnn}. O modelo Word2Vec, proposto por \textcite{mikolov2013word2vec}, introduziu embeddings capazes de capturar relações semânticas complexas, seguido pelo GloVe, de \textcite{pennington2014glove}, que combinava estatísticas globais de coocorrência com propriedades locais do texto. Na tradução automática, os métodos estatísticos deram lugar aos sistemas baseados em redes neurais, especialmente após a introdução do modelo de atenção por \textcite{bahdanau2015attention}.

A partir de 2017 até o presente momento, a PLN passou por uma transformação profunda com o surgimento da arquitetura Transformer, apresentada por \cite{vaswani2017attention} no artigo "Attention is All You Need". Ao eliminar o uso de redes recorrentes e basear o processamento em mecanismos de atenção, os Transformers permitiram maior paralelização no treinamento e obtiveram resultados superiores em diversas tarefas de PLN, como tradução, classificação e resposta a perguntas. Esse avanço abriu caminho para a era dos modelos pré-treinados em larga escala. Em 2018, o BERT (Bidirectional Encoder Representations from Transformers) \cite{devlin2018bert} introduziu um novo paradigma: pré-treinamento em grandes volumes de texto seguido de ajuste fino (fine-tuning) para tarefas específicas. BERT e suas variantes como RoBERTa, XLNet e ALBERT superaram modelos anteriores em benchmarks como GLUE e SQuAD, consolidando o uso de embeddings contextuais profundos. A partir de 2019, os modelos generativos ganham destaque com o GPT-2 \cite{radford2019gpt2}, seguido por GPT-3 \cite{brown2020language}, que popularizou o conceito de few-shot learning, permitindo resolver tarefas complexas apenas com instruções em linguagem natural. O GPT-3, com 175 bilhões de parâmetros, tornou-se um marco em geração de texto, raciocínio e aplicações comerciais.

\section{Modelos}

\subsection{GPT}

O GPT (Generative Pre-trained Transformer) constitui uma família de modelos de linguagem desenvolvida pela OpenAI, baseada na arquitetura Transformer proposta inicialmente por \citeauthor{vaswani2017attention}. Sua implementação segue especificamente a variante decoder-only, na qual todas as camadas do modelo atuam como blocos de decodificação com mecanismos de self-attention unidirecional \cite{openai2024gpt4technicalreport}. Esse tipo de arquitetura permite que o modelo opere de forma auto-regressiva, gerando cada token com base na probabilidade condicional do próximo elemento dada a sequência anterior, conforme amplamente adotado em modelos autoregressivos de geração de linguagem \cite{brown2020language}.
O processo de treinamento do GPT é tradicionalmente dividido em duas fases. A primeira é o pré-treinamento, no qual o modelo é exposto a grandes volumes de dados textuais não estruturados com o objetivo de aprender regularidades linguísticas e padrões estatísticos gerais por meio de aprendizado auto-supervisionado \cite{brown2020language}. A segunda etapa consiste no ajuste fino (fine-tuning), que pode ser realizado de maneira supervisionada ou mediante técnicas de alinhamento com feedback humano, como o RLHF (Reinforcement Learning from Human Feedback), visando adaptar o comportamento do modelo para tarefas específicas e aumentar sua segurança e confiabilidade \cite{openai2024gpt4technicalreport}.
Ao longo de suas versões  como GPT-3, GPT-4 e GPT-5  esses modelos demonstraram avanços substanciais em raciocínio, coerência discursiva e capacidade de seguir instruções complexas, estabelecendo um novo paradigma na área de LLM's. Pesquisas e relatórios técnicos da OpenAI destacam a evolução contínua em desempenho, robustez e alinhamento ético, definindo o GPT como uma das arquiteturas de referência no desenvolvimento de sistemas de IA generativa \cite{openai2024gpt4technicalreport}.


\subsection{Gemini}

O Gemini é um modelo multimodal de grande escala desenvolvido pela Google DeepMind, concebido desde o início para processar de forma integrada múltiplas modalidades, incluindo texto, imagens, áudio, vídeo e código \cite{geminiteam2025geminifamilyhighlycapable}. Em contraste com modelos estritamente auto-regressivos baseados apenas em arquiteturas decoder-only, como o GPT, o Gemini adota uma arquitetura multimodal unificada, estruturada por componentes de encoders e decoders, permitindo que diferentes modalidades sejam representadas e integradas de maneira coerente antes da geração de saídas \cite{geminiteam2025geminifamilyhighlycapable}.
Essa arquitetura híbrida possibilita ao modelo realizar raciocínio multimodal de maneira mais eficiente e com maior profundidade contextual, uma vez que o sistema é capaz de analisar relações entre sinais perceptuais e linguísticos simultaneamente, evitando a necessidade de modelos auxiliares ou módulos externos de visão computacional. De acordo com o relatório técnico do Gemini, essa integração arquitetural melhora substancialmente o desempenho em tarefas que envolvem interpretação de imagens, análise de vídeos, reconhecimento de áudio e compreensão combinada de múltiplos formatos de dados \cite{geminiteam2025geminifamilyhighlycapable}.
O treinamento do Gemini também se distingue pelo uso de um conjunto de dados multimodal de larga escala, composto por textos, imagens, documentos, áudio e conteúdos de código, o que permite ao modelo desenvolver representações alinhadas entre modalidades distintas. Essa diversidade de dados promove melhor capacidade de generalização e torna o modelo particularmente adequado para aplicações que requerem integração entre informação verbal e perceptual, como sistemas de análise visual, interpretação automática de vídeos, resolução de problemas multimodais e suporte a tarefas complexas que envolvem diferentes formas de representação simbólica \cite{geminiteam2025geminifamilyhighlycapable}.


\subsection{DeepSeek}

O DeepSeek é um modelo de linguagem de código aberto desenvolvido pela DeepSeek AI que se destacou por apresentar alto desempenho aliado a um custo computacional significativamente reduzido, tornando-se uma alternativa competitiva em relação a modelos proprietários de larga escala \cite{deepseek2024llm}. Assim como outros modelos autoregressivos modernos, sua arquitetura segue o paradigma decoder-only Transformer, originalmente baseado na formulação de \citeauthor{vaswani2017attention}, porém incorpora um conjunto de otimizações estruturais e de treinamento voltadas para a eficiência \cite{deepseek2024llm}.
Entre as principais técnicas adotadas está o DeepSeekMoE, uma arquitetura inovadora de Mixture-of-Experts (MoE) que utiliza segmentação de especialistas em grão fino (fine-grained expert segmentation) e isolamento de especialistas compartilhados. Essa abordagem permite reduzir drasticamente a quantidade de parâmetros ativados durante a inferência, preservando a expressividade do modelo e diminuindo o custo computacional sem comprometer o desempenho geral \cite{dai2024deepseekmoe}.
Além disso, o DeepSeek utiliza otimizações avançadas de paralelismo, permitindo aproveitar de forma mais eficiente múltiplas GPUs ou hardwares equivalentes durante o treinamento \cite{deepseek2024llm}. Esse tipo de estratégia reduz significativamente o tempo de convergência e o custo operacional em comparação com arquiteturas tradicionais densas.
O modelo também foi projetado para execução eficiente e democratização do acesso, ampliando sua adoção pela comunidade acadêmica e por organizações sem acesso a infraestrutura computacional de grande porte \cite{dai2024deepseekmoe}. Dessa forma, o DeepSeek se consolida como um exemplo relevante de como arquiteturas abertas e otimizadas podem viabilizar o uso de modelos de linguagem de grande escala.

\section{Trabalhos correlatos}\label{correlatos}

\textcite{nunes2023evaluating} em seu trabalho analisou o uso de LLM's na resolução de questões do exame nacional do ensino médio, utilizando técnicas diferentes de \text{prompts}, nesse trabalho foram utilizados os exames das edições de 2009 até 2019 e também há 2022. As técnicas de prompt utilizadas foram a zero-shot, few-shot e few-shot com Chain-of-Thought (CoT). O modelo GPT-4 obteve um resultado significativo com o uso da técnica CoT, e, analisando pelo campo da matemática, obteve um aumento mais expressivo quando se analisa as outras áreas utilizando essa técnica. No modelo GPT 3.5, o uso do CoT também refletiu uma melhoria nas resoluções de questões de matemática, no entanto, no GPT 4, outras áreas não foram afetadas; porém, nesse modelo, o uso do CoT acompanhou um declínio nas resoluções das questões de ciências da natureza e linguagens. Portanto, o estudo mostrou que o modelo GPT 4 possui uma alta capacidade de resolver as questões do Enem e retornar \textit{insigts} valiosos em sua resposta. Essa capacidade é vista como uma ferramenta educacional promissora, pois pode aprimorar a compreensão dos alunos sobre conceitos complexos e apoiar seu processo de aprendizagem, oferecendo respostas mais transparentes e informativas para questões desafiadoras.

No trabalho de \textcite{viegas2024avaliando}, em que se investigou a capacidade das LLM's em igualar ou superar o desempenho humano no POSCOMP (Exame Nacional para Ingresso na Pós-Graduação em Computação), utilizando os modelos ChatGPT-4, Gemini 1.0 Advanced, Claude 3 Sonnet e Le Chat Mistral Large – utilizando as edições de 2022 e 2023 dos exames. A pesquisa foi dividida em duas etapas, a primeira em analisar os modelos na resolução das questões por meio de interpretação de imagens das questões, e a segunda maneira foi por meio da resolução das questões por meio de prompt textual convertido para o idioma do inglês. As alucinações foram menos frequentes na avaliação baseada em texto. Os modelos variaram em seus níveis de explicação; o Gemini e o Claude consistentemente ofereceram explicações mais abrangentes, enquanto o ChatGPT-4 e o Mistral ocasionalmente optaram por respostas mais diretas. Por fim, o estudo concluiu que os modelos LLM's têm boas e consideráveis respostas ao resolver questões do POSCOMP, o modelo que mais se destacou foi o ChatGPT-4, pois ele superou outros modelos em ambos os tipos de testes na metodologia. Porém, para ambos os modelos, a interpretação de imagens ainda é um desafio a ser melhorado em versões futuras dessas LLM's.

No trabalho de \textcite{raposo2024avaliaccao} investiga a capacidade de Grandes Modelos de Linguagem (LLM's) em responder a questões objetivas do Exame Nacional do Ensino Médio (ENEM). Os LLM's surgiram como uma "quebra de paradigma" na Inteligência Artificial (IA) e são amplamente utilizados, com o ChatGPT (OpenAI) sendo um dos principais responsáveis pela sua popularização. O estudo ressalta que a maioria das avaliações de LLM's se limita ao contexto da língua inglesa, sem testes eficazes em cenários globalizados como o brasileiro. Nessa pesquisa utilizou-se as LLM's: Llama 2, GPT-3.5 e GEMINI 1.0 Pro em questões de múltipla escolha do ENEM de 11 edições (2011-2013, 2015-2020, 2022, 2023). Na metodologia desse trabalho buscou fazer uma integração do envio das questões por meio de API das LLM's e também fazer váriações na temperatura das respostas entregues pela as mesmas. No geral dos acertos o Gemini obteve um percentual maior nas questões com a temperatura definida como a padrão das LLM's, resultados melhores que o GPT-3.5 e o Llama 2. Com a temperatura do modelo calibrada em 0 para dar respostas mais deterministicas, todos os modelos obtiveram melhorias na quantidade de acertos, no entando, o Gemini ainda se saiu superior aos demais. Portanto o estudo mostrou que no contexto de responder as questões do Enem, o LLM da Google (Gemini) mostrou uma capacidade superior que o GPT-3.5 e o Llama 2. Porém todos os LLM's mostraram maior dificuldade em Matemática e Ciências da Natureza.

\textcite{rodrigues2025llms} investigaram a capacidade das LLM's em sistemas de resposta a perguntas educacionais, que facilitam o aprendizado adaptativo e respondem às dúvidas dos alunos. O estudo investiga como as LLM's podem ser integrados eficientemente em sistemas educacionais de perguntas e respostas para atender a diversas necessidades educacionais.  Nesse estudo foram utilizados os modelos GPT-4 o modelo mais atual da OpenIA e também o Sabiá (um LLM de código aberto, otimizado especificamente para o português brasileiro, baseado nos modelos LLaMA) e o uso dela visa abordar a carência de consideração de LLM's nativos na pesquisa. Foi criado um questionario de 70 questões em que foram baseadas na Base Nacional Comum Curricular (BNCC) do Brasil com 40 delas sendo de Matématico e 30 da Lingua Portuguesa, e destinadas a alunos do terceiro ano do ensino fundamental, representando o momento em que os alunos completam a alfabetização. Para esse trabalho foram utilizadas questões além das de multipla escolha, como as de preencher lacunas no texto e dissertativas curtas. Ambos os modelos demonstraram um desempenho forte e confiável, com uma pontuação média geral de 9,79 de 10. Portanto o estudo conclui que os LLM's, tanto o GPT-4 quanto o Sabiá, demonstram fortes capacidades na resolução de questões educacionais em português brasileiro. Essa consistência indica que ambos os modelos são hábeis em lidar com questões em português, refletindo um desempenho confiável até mesmo com questões em outro idioma não-inglês.